{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with Text Data\n",
    "\n",
    "Often raw data comes from all kinds of text documents: structured documents (HyperText Markup Language/HTML, eXtensible Markup Language/XML, Comma Separated Values/CSV, and JavaScript Object Notation/JSON files) or unstructured documents (plain, human-readable text). \n",
    "\n",
    "As a matter of fact, unstructured text is perhaps the hardest data source to work with because the processing software has to infer the meaning of the data items.\n",
    "\n",
    "#### Hint\n",
    "Azure Notebooks intentionally restricts access to external URLs. This is most likely to prevent people from using the Notebooks service to perform denial of service attacks to other sites.\n",
    "\n",
    "\n",
    "# Processing HTML Files\n",
    "\n",
    "Module **BeautifulSoup** is used for parsing, accessing, and modifying HTML and XML documents. \n",
    "You can construct a BeautifulSoup object from a markup string, a markup file, or a URL of a markup document on the Web.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 403: Forbidden",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-3abcca23cfc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# Construct soup from a Web document\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m# Remember that urlopen() does not add \"http://\"!\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0msoup3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBeautifulSoup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"http://www.networksciencelab.com/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"lxml\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3_410/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    160\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_410/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    469\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_410/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    579\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 581\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_410/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    507\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 509\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    510\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_410/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3_410/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    587\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 403: Forbidden"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import urlopen\n",
    "\n",
    "# Construct soup from a string\n",
    "soup1 = BeautifulSoup(\"<HTML><HEAD>«headers»</HEAD>«body»</HTML>\", \"lxml\")\n",
    "\n",
    "# Construct soup from a local file\n",
    "#soup2 = BeautifulSoup(open(\"myDoc.html\"), \"lxml\")\n",
    "\n",
    "# Construct soup from a Web document\n",
    "# Remember that urlopen() does not add \"http://\"!\n",
    "soup3 = BeautifulSoup(urlopen(\"http://www.networksciencelab.com/\"), \"lxml\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "**BeautifulSoup** comes with four pre-installed parsers:\n",
    "* \"html.parser\" (default, very fast, not very lenient; used for “simple” HTML documents);\n",
    "* \"lxml\" (very fast, lenient);\n",
    "* \"xml\" (for XML files only);\n",
    "* \"html5lib\" (very slow, extremely lenient; used for HTML documents with complicated structure, or for all HTML documents if the parsing speed is not an issue).\n",
    "\n",
    "When the soup is ready, you can pretty print the original markup document with the function *soup.prettify()*.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<html>\\n <head>\\n </head>\\n <body>\\n  <p>\\n   «headers»«body»\\n  </p>\\n </body>\\n</html>'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup1.prettify()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function soup.get_text() returns the text part of the markup document with all tags removed. Use this function to convert markup to plain text when it’s the plain text you are interested in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nMy document\\nMain text.\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "htmlString = '''\n",
    "    <HTML>\n",
    "    <HEAD><TITLE>My document</TITLE></HEAD>\n",
    "    <BODY>Main text.</BODY></HTML>\n",
    "'''\n",
    "soup = BeautifulSoup(htmlString, \"lxml\")\n",
    "soup.get_text()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often markup tags are used to locate certain file fragments. For example, you might be interested in the first row of the first table.\n",
    "\n",
    "BeautifulSoup uses a consistent approach to all vertical and horizontal relations between tags. The relations are expressed as attributes of the tag objects and resemble a file system hierarchy.\n",
    "\n",
    "+ The first cell in the first row of the first table is *soup.body.table.tr.td* .\n",
    "\n",
    "+ Any tag t has a name t.name, a string value (t.string with the original content and a list of t.stripped_strings with removed white spaces), the parent t.parent, the next t.next and the previous t.prev tags, and zero or more children t.children (tags within tags).\n",
    "\n",
    "+ BeautifulSoup developers implemented access to HTML tag attributes through a Python dictionary interface. If object t represents a hyperlink, then the string value of the destination of the hyperlink is t[\"href\"].string.\n",
    "\n",
    "+ Perhaps the most useful soup functions are *soup.find()* and *soup.find_all()*, which find the first instance or all instances of a certain tag. \n",
    "\n",
    "**Examples:**\n",
    "+ All instances of the H2-tag:\n",
    "\n",
    "    level2headers = soup.find_all(\"H2\")\n",
    "    \n",
    "    \n",
    "+ All bold or italic formats:\n",
    "\n",
    "\tformats = soup.find_all([\"i\", \"b\", \"em\", \"strong\"])\n",
    "\n",
    "\n",
    "+ All tags that have a certain attribute (for example, id=\"link3\"):\n",
    "\n",
    "    soup.find(id=\"link3\")\n",
    "  \n",
    "  \n",
    "+ All hyperlinks and also the destination URL of the first link, using either the dictionary notation of the tag.get() function:\n",
    "\n",
    "    links = soup.find_all(\"a\")\n",
    "    \n",
    "    firstLink = links[0][\"href\"]\n",
    "    \n",
    "    /# or\n",
    "    \n",
    "    firstLink = links[0].get(\"href\")\n",
    "    \n",
    "    Both expressions fail if the attribute is not present. You must use the *tag.has_attr()* function to check the presence of an attribute before you extract it.\n",
    "\n",
    "\n",
    "\n",
    "The following expression combines BeautifulSoup and list comprehension to extract all links and their respective URLs and labels (useful for recursive Web crawling):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with urlopen(\"http://www.networksciencelab.com/\") as doc:\n",
    "    soup = BeautifulSoup(doc, \"lxml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Networks of Music Groups as Success Predictors', 'http://www.slideshare.net/DmitryZinoviev/networks-of-music-groups-as-success-predictors'), ('Network Science Workshop', 'http://www.slideshare.net/DmitryZinoviev/workshop-20212296'), ('Resilience in Transaction-Oriented Networks', 'http://www.slideshare.net/DmitryZinoviev/resilience-in-transactional-networks'), ('Peer Ratings in Massive Online Social Networks', 'http://www.slideshare.net/DmitryZinoviev/peer-ratings-in-massive-online-social-networks'), ('Semantic Networks of Interests in Online NSSI Communities', 'http://www.slideshare.net/DmitryZinoviev/presentation-31680572'), ('Towards an Ideal Store', 'http://www.slideshare.net/DmitryZinoviev/10-monthsymposiumbeta'), ('D.Zinoviev, \"Analyzing Cultural Domains with Python,\"', 'https://media.pragprog.com/newsletters/2016-04-06.html'), ('D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\"', 'http://dhj.sagepub.com/content/2/2055207616642118.full'), ('D.Zinoviev, \"The Pain of Complexity,\"', 'http://www.mitpressjournals.org/doi/abs/10.1162/LEON_a_01271#.VzOvwHUrKzc'), ('D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\"', 'http://link.springer.com/chapter/10.1007/978-3-319-16112-9_18')]\n"
     ]
    }
   ],
   "source": [
    "links = []\n",
    "for link in soup.find_all(\"a\"):\n",
    "    if link.has_attr(\"href\"):\n",
    "        links.append( (link.string, link[\"href\"]) )\n",
    "        \n",
    "print(links[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Networks of Music Groups as Success Predictors', 'http://www.slideshare.net/DmitryZinoviev/networks-of-music-groups-as-success-predictors'), ('Network Science Workshop', 'http://www.slideshare.net/DmitryZinoviev/workshop-20212296'), ('Resilience in Transaction-Oriented Networks', 'http://www.slideshare.net/DmitryZinoviev/resilience-in-transactional-networks'), ('Peer Ratings in Massive Online Social Networks', 'http://www.slideshare.net/DmitryZinoviev/peer-ratings-in-massive-online-social-networks'), ('Semantic Networks of Interests in Online NSSI Communities', 'http://www.slideshare.net/DmitryZinoviev/presentation-31680572'), ('Towards an Ideal Store', 'http://www.slideshare.net/DmitryZinoviev/10-monthsymposiumbeta'), ('D.Zinoviev, \"Analyzing Cultural Domains with Python,\"', 'https://media.pragprog.com/newsletters/2016-04-06.html'), ('D. Zinoviev, D. Stefanescu, G. Fireman, and L. Swenson, \"Semantic networks of interests in online non-suicidal self-injury communities,\"', 'http://dhj.sagepub.com/content/2/2055207616642118.full'), ('D.Zinoviev, \"The Pain of Complexity,\"', 'http://www.mitpressjournals.org/doi/abs/10.1162/LEON_a_01271#.VzOvwHUrKzc'), ('D.Zinoviev, Z.Zhu, and K.Li, \"Building mini-categories in product networks,\"', 'http://link.springer.com/chapter/10.1007/978-3-319-16112-9_18')]\n"
     ]
    }
   ],
   "source": [
    "# shorter with list comprehension\n",
    "links = [(link.string, link[\"href\"])\n",
    "    for link in soup.find_all(\"a\")\n",
    "    if link.has_attr(\"href\")]\n",
    "\n",
    "print(links[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling CSV Files\n",
    "\n",
    "Comma separated values (CSV) is a structured text file format used to store and move tabular or nearly tabular data. It dates back to 1972 and is a format of choice of Microsoft Excel, OpenOffice Calc, and other spreadsheet software.\n",
    "\n",
    "Data.gov,1 a U.S. government Web site that provides access to publicly available data, alone provides 11,783 data sets in the CSV format.\n",
    "\n",
    "A CSV file consists of columns representing variables and rows representing records. (Data scientists often call them observations.)\n",
    "\n",
    "The fields in a record are typically separated by commas, but other delimiters, such as tabs (tab separated values [TSV]), colons, semicolons, and vertical bars, are also common.\n",
    "\n",
    "Keep in mind that sometimes what looks like a delimiter is not a delimiter at all. To allow delimiter-like characters within a field as a part of the variable value (as in ...,\"Hello, world\",...), enclose the fields in quote characters.\n",
    "\n",
    "Python module csv provides a CSV reader and a CSV writer.\n",
    "\n",
    "Both objects take a previously opened text file handle as the first parameter (in the example, the file is opened with the newline='' option to avoid the need to strip the lines). You may provide the delimiter and the quote character, if needed, through the optional parameters delimiter and quotechar. Other optional parameters control the escape character, the line terminator, and so on. \n",
    "\n",
    "    with open(\"somefile.csv\", newline='') as infile:\n",
    "\t    reader = csv.reader(infile, delimiter=',', quotechar='\"')\n",
    "\n",
    "The first record of a CSV file often contains column headers and may be treated differently from the rest of the file. This is not a feature of the CSV format itself, but simply a common practice.\n",
    "\n",
    "A CSV reader provides iterator interface for use in a for loop. The iterator returns the next record as a list of string fields. The reader does not convert the fields to any numeric data type (it’s still our job!) and does not strip them of the leading white spaces, unless instructed by passing the optional parameter *skipinitialspace=True*.\n",
    "\n",
    "\n",
    "In the following example we’ll use the csv module to extract the “Answer.Age” column from a CSV file. We’ll assume that the index of the column is not known, but the that column definitely exists.\n",
    "\n",
    "First, open the file and read the data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading JSON Files\n",
    "JavaScript Object Notation (JSON) is a lightweight data interchange format.\n",
    "\n",
    "Unlike pickle, JSON is language independent, but more restricted in terms of data representation.\n",
    "\n",
    "Many popular Web sites, such as Twitter, Facebook, and Yahoo! Weather provide APIs that use JSON as the data interchange format.\n",
    "\n",
    "JSON supports the following data types:\n",
    "+ atomic data types—strings, numbers, true, false, null\n",
    "+ arrays - an array corresponds to a Python list; it is enclosed in square brackets []; the items in an array do not have to be of the same data type:\n",
    "\n",
    "    [1, 3.14, \"a string\", true, null]\n",
    "\n",
    "\n",
    "+ Objects - an object corresponds to a Python dictionary; it is enclosed in curly braces {}; every item consists of a key and a value, separated by a colon:\n",
    "     \n",
    "     {\"age\" : 37, \"gender\" : \"male\", \"married\" : true}\n",
    "     \n",
    "\n",
    "+ any recursive combinations of arrays, objects, and atomic data types (arrays of objects, objects with arrays as item values, and so on)\n",
    "\n",
    "\n",
    "Storing complex data into a JSON file is called serialization. \n",
    "\n",
    "The opposite operation is called deserialization. \n",
    "\n",
    "Python handles JSON serialization and deserialization via the functions in the module json.\n",
    "\n",
    "Function *dump()* exports (“dumps”) a representable Python object to a previously opened text file. \n",
    "\n",
    "Function *dumps()* exports a representable Python object to a text string (for the purpose of pretty printing or interprocess communications).\n",
    "\n",
    "Both functions are responsible for serialization.\n",
    "\n",
    "Function *loads()* converts a valid JSON string into a Python object (it “loads” the object into Python). This conversion is always possible. \n",
    "\n",
    "In the same spirit, function *load()* converts the content of a previously opened text file into one Python object. It is an error to store more than one object in a JSON file, but if an existing file still contains more than one object, You can read it as text, convert the text into an array of objects (by adding square brackets around the text and comma separators between the individual objects), and use *loads()* to deserialize the text to a list of objects.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"ObjectInterpolator\": 1629, \"PointInterpolator\": 1675, \"RectangleInterpolator\": 2042}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "object1 = {'ObjectInterpolator': 1629,  'PointInterpolator': 1675, 'RectangleInterpolator': 2042}\n",
    "# Serialize an object to a string\n",
    "json_string = json.dumps(object1)\n",
    "print(json_string)\n",
    "\n",
    "# Parse a string as JSON\n",
    "object2 = json.loads(json_string)\n",
    "\n",
    "# Tadaaam! Despite four painful conversions, object1 and object2 still have the same value.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Your Turn\n",
    "\n",
    "# Broken Link Detector\n",
    "\n",
    "Write a program that, given a URL of a Web page, reports the names and destinations of broken links in the page. \n",
    "\n",
    "For the purpose of this exercise, a link is broken if an attempt to open it with urllib.request.urlopen() fails.\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
